# Human Activity Recognition (HAR) using CNN and Smartphone Accelerometer Data

This project focuses on Human Activity Recognition (HAR) using time-series data collected from a 3-axis accelerometer. The data represents six physical activities â€” walking, walking upstairs, walking downstairs, sitting, standing, and laying â€” performed by volunteers wearing smartphones. We use a 1D Convolutional Neural Network (CNN) to classify these activities based on temporal patterns in the sensor data.

The dataset has been preprocessed into fixed-size windows (128 samples per window) with a sampling frequency of 50Hz. After loading and preprocessing, the model is trained and validated using a typical 85-15 split and evaluated on a held-out test set.

To ensure edge compatibility, the trained Keras model is converted to TensorFlow Lite (TFLite) format, followed by post-training quantization for optimized deployment on low-power devices such as the ESP32 microcontroller. The quantized model is also exported as a C header file for direct integration into embedded firmware.

The project includes full evaluation metrics, such as confusion matrix, accuracy, F1 scores, and inference timing for both TFLite and quantized versions. This pipeline demonstrates an end-to-end workflow from model training to embedded deployment, making it suitable for real-time activity recognition applications on resource-constrained devices.


## ğŸ“ Dataset

The original dataset is the [UCI HAR Dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones), collected from 30 volunteers using a Samsung Galaxy S II smartphone.

**Note**: Preprocessed CSV versions (`accelerometer_3axis_time_series_train.csv`, etc.) must be placed in the appropriate folder (see `src/train_model.py`).

#  ğŸ“‚ Dataset Structure Overview 

# ğŸ“ CSV Files Used:
 ----------------------------------------------------------------------------------
 1. accelerometer_3axis_train.csv   â†’ Shape: (7352, 128, 3)
 2. accelerometer_3axis_test.csv    â†’ Shape: (2947, 128, 3)
 3. y_train_labels.csv              â†’ Shape: (7352, 6)   # One-hot encoded labels
 4. y_test_labels.csv               â†’ Shape: (2947, 6)   # One-hot encoded labels

# ğŸ§  Data Dimensions:
 ----------------------------------------------------------------------------------
 - Each sample = 128 time steps (over 2.56 seconds) of 3-axis accelerometer data
 - Shape per sample = (128, 3) â†’ [X, Y, Z] acceleration readings
 - Final shape for training:   X_train â†’ (6249, 128, 3),  y_train â†’ (6249, 6)
 - Final shape for validation: X_val   â†’ (1103, 128, 3),  y_val   â†’ (1103, 6)
 - Final shape for testing:    X_test  â†’ (2947, 128, 3),  y_test  â†’ (2947, 6)

# ğŸ“Œ Class Labels (6 total):
 ----------------------------------------------------------------------------------
 0 â†’ WALKING
 1 â†’ WALKING_UPSTAIRS
 2 â†’ WALKING_DOWNSTAIRS
 3 â†’ SITTING
 4 â†’ STANDING
 5 â†’ LAYING

# ğŸ“ Notes:
 - The CSVs were generated from UCI HAR Dataset inertial signal files.
 - Values are normalized and suitable for training with 1D CNN models.
 - Data split: 85% train / 15% validation from original training set.

# ===========================================================================================

## ğŸ§  Model Architecture

A 1D Convolutional Neural Network (CNN) is used:
- Input shape: (128, 3) â€” 3-axis accelerometer data in time windows
- Conv1D â†’ MaxPool â†’ Conv1D â†’ MaxPool â†’ Flatten â†’ Dense â†’ Dropout â†’ Output
- Output: Softmax layer for 6-class classification

## ğŸ“Š Results

| Metric           | Value |
|------------------|-------|
| Validation Acc   | ~X.XX |
| Test Accuracy    | ~X.XX |
| Macro F1-Score   | ~X.XX |
| Micro F1-Score   | ~X.XX |

## ğŸ› ï¸ Files & Directories

- `src/`: Python scripts for training, evaluation, model export
- `models/`: Trained Keras, TFLite, and C header model
- `data/`: Dataset instructions or metadata
- `notebooks/`: Optional explorations
- `requirements.txt`: Required Python packages

## ğŸ“¦ Dependencies

Install dependencies using:

```bash
pip install -r requirements.txt
